{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.99948626]\n",
      "[1. 1.]\n",
      "[1. 1.]\n",
      "[1. 1.]\n",
      "[0.99899291 0.9999413 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.signal import lfilter, lfilter_zi\n",
    "#myxcorr\n",
    "def myxcorr(x,y,lags):\n",
    "    '''\n",
    "    Computes auto- and corr-correlation matrices Rxx, Rxy and ryy defined as\n",
    "    (after the mean is subtracted from x and y):\n",
    "\n",
    "        Rxx(l)= sum_n x'(n)*x(n+l)\n",
    "        Rxy(l)= sum_n x'(n)*y(n+l)\n",
    "        ryy   = sum_n |y(n)|^2\n",
    "\n",
    "\n",
    "    This is computed in the frequency domain, returning only zero and\n",
    "    positive delays l = 0 ... lags-1. Note that these definitions differ from\n",
    "    the standard definition of the cross correlation and from matlab's\n",
    "    conventional xcorr() implementation. Here y is delayed, not x, which is\n",
    "    equivalent to keeping the negative delays in the standard definition.\n",
    "\n",
    "    Rxx and Rxy are arranged as required to implement conventional MIMO\n",
    "    system identification (see example below). Rxx is a square block-Toeplitz\n",
    "    auto-correlation matrix of size sum(lags) and Rxy is a cross-correlation\n",
    "    block-matrix of size [sum(lags), ydim]. lags is a vector of lags used for\n",
    "    each of xdim columns in x. \n",
    "\n",
    "    x and y are required input, all others are optional. lags defaults to\n",
    "    size(x,1)-1 and is converted into a vector of size xdim if it is given as\n",
    "    a scalar.  x and y should be arranged as time by dimensions. y should\n",
    "    not be longer in time than x; if necessary, pad x with zeros before\n",
    "    calling.\n",
    "\n",
    "    Correlations are computed using Toeplitz matrices. x or y may contain NaN\n",
    "    which are removed from the sum over n which have NaN in any row of y, or\n",
    "    do not have a max(lags) history in the rows of x. T is returned to report\n",
    "    how many samples were used. The max(lags) samples at the start are also\n",
    "    removed (this is known as the covariance method, see Ljung, System\n",
    "    Identification, Ch. 10.1). Mean subtraction is done with the mean of\n",
    "    valid samples only.\n",
    "\n",
    "    This function can be used for MIMO FIR identification as follows: \n",
    "\n",
    "    [Rxx,Rxy] = myxcorr(x,y,lags);\n",
    "    h = inv(Rxx)*Ry;\n",
    "    yest = filterMIMO(h,x,lags);\n",
    "    error = y-yest;\n",
    "\n",
    "    (c) (matlab) April 21, 2021, Lucas C Parra\n",
    "                 12/12/2023, last version, Lucas Parra\n",
    "    (c) (python) April 12, 2024, Aimar Silvan, based on matlab version 12/12/2023\n",
    "    '''\n",
    "    \n",
    "    # Deal with inputs\n",
    "    if lags is None:\n",
    "        lags = x.shape[0] - 1 -1\n",
    "    else:\n",
    "        lags = lags*np.ones((x.shape[1],1))\n",
    "    \n",
    "    # Compute correlations up to largest possible lag\n",
    "    Q = int(np.max(lags))\n",
    "    \n",
    "    # Find valid samples without NaN in all rows of Y and Q history of all X rows\n",
    "    # z = np.empty((Q-1))\n",
    "    # z[:] = np.nan\n",
    "    z1 = lfilter_zi(np.ones((Q)),1)\n",
    "    z1 = z1*np.nan\n",
    "    filtered, _ = lfilter(np.ones((Q)),1,np.sum(x,1),zi = z1)\n",
    "    valid = ~np.isnan(filtered + np.sum(y,1))\n",
    "    \n",
    "    # number of valid samples\n",
    "    T = sum(valid)\n",
    "    \n",
    "    # remove offset\n",
    "    x = x - np.mean(x[valid,:],0)\n",
    "    y = y - np.mean(y[valid,:],0)   \n",
    "\n",
    "    # #compute correlations with block-Toeplitz matrices\n",
    "    X = np.zeros((x.shape[0], int(np.sum(lags))))\n",
    "    for i in range(x.shape[1]-1, -1, -1):\n",
    "        startidx = int(np.sum(lags[0:i]))\n",
    "        endidx = startidx + int(lags[i,0])\n",
    "        toeplitz_matrix = toeplitz(x[:, i], np.concatenate(([x[0, i]], np.zeros(int(lags[i, 0])-1))))\n",
    "        X[:, startidx:endidx] = toeplitz_matrix\n",
    "\n",
    "    Rxx = X[valid, :].T @ X[valid, :]\n",
    "    Rxy = X[valid, :].T @ y[valid, :]\n",
    "    \n",
    "    # Power of y\n",
    "    ryy = np.sum(np.abs(y[valid,:])**2,0)\n",
    "    \n",
    "    return Rxx, Rxy, ryy, T \n",
    "    \n",
    "    #testcode\n",
    "    #data is same from 'testcode fir MIMO  MA identification' in 'matlab/myxcorr.m'\n",
    "    import scipy.io as sio\n",
    "    x = sio.loadmat('testdata/x.mat')['x']\n",
    "    y = sio.loadmat('testdata/y.mat')['y']\n",
    "    L = 10\n",
    "    [Rxx,Rxy,ryy,T] = myxcorr(x,y,L)\n",
    "\n",
    "\n",
    "# basis\n",
    "import numpy as np\n",
    "from scipy.signal import windows\n",
    "def basis(T,n,type):\n",
    "    '''\n",
    "    b=basis(T,n,type) makes basis functions of type 'hanning' or 'normal'. T\n",
    "    is the length of the basis. n is how many to use. Typically T>>n, if the\n",
    "    goal is to represent a filter with fewer parameters. Omit output argument\n",
    "    to see how the basis functions look.\n",
    "    '''\n",
    "    \n",
    "    r = T / n\n",
    "    b = np.zeros((T, n))\n",
    "\n",
    "    if type == 'hanning':\n",
    "        for i in range(n):\n",
    "            b[:int(round(r*4)), i] = windows.hann(int(round(r*4)))\n",
    "        b = np.flipud(b[int(np.floor(r)):T, :])\n",
    "\n",
    "    elif type == 'normal':\n",
    "        t = np.arange(1, T+1)\n",
    "        for i in range(n):\n",
    "            b[:, i] = np.exp(-np.power(t - (i * r), 2) / np.power(r, 2))\n",
    "\n",
    "    else:\n",
    "        b = np.eye(T)\n",
    "        \n",
    "    return b\n",
    "    \n",
    "\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "from scipy.linalg import solve\n",
    "# fit_model\n",
    "def fit_model(Rxx, Rxy, ryy, gamma, base):\n",
    "    # apply basis functions, if available \n",
    "    if base[0] is not None:\n",
    "        B = block_diag(*base)\n",
    "        Rxx = B.T @ Rxx @ B\n",
    "        Rxy = B.T @ Rxy\n",
    "        \n",
    "    # Regularizer\n",
    "    Gamma = gamma * np.diag(np.diag(Rxx)) # Tikhonov, scaled for all variables to be regularized equally, regardless of magnitude\n",
    "\n",
    "    # Least squares estimate with regularization\n",
    "    h = solve(Rxx + Gamma, Rxy)\n",
    "\n",
    "    # mean error square\n",
    "    Rxyest = Rxx @ h\n",
    "    s2 = (np.sum(h * Rxyest, 0) - 2 * np.sum(h * Rxy,0) + ryy).T\n",
    "\n",
    "    # Bias term for ridge regression bias -- see Babadi derivation \n",
    "    Bias = np.sum((Rxy - Rxyest) * solve(Rxx, Rxy - Rxyest),0).T / s2 / 2 if gamma > 0 else 0\n",
    "\n",
    "    return h, s2, Bias\n",
    "\n",
    "# varx\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "def varx(Y, na, X, nb, gamma):\n",
    "    '''\n",
    "    model = varx(Y,na,X,nb,gamma) fits an vectorial ARX model to the MIMO\n",
    "    system output Y with input X by minimizing the equation error e(t), i.e.\n",
    "    equation error model:\n",
    "\n",
    "    Y(t) = A*Y(t-1) + B*X(t) + e(t)\n",
    "\n",
    "    where * represents a convolution.  The model contains the following\n",
    "    variables, stored as stucture elements:\n",
    "\n",
    "    model = A, B, A_pval, B_pval, A_Deviance,B_Deviance, T\n",
    "\n",
    "    A and B are filter model parameters found with conventional least squares\n",
    "    with ridge regression. They are stored as tensor of size [na,ydim,ydim]\n",
    "    and [nb,ydim,xdim] respectively. na and nb are the legth of the filters.\n",
    "    gamma is the regularization for the ridge (shrinkage) regularization and\n",
    "    defaults to 0 and should not be selected larger than 1. Note that x(t)\n",
    "    represents the history including the current sample in the input. Thus,\n",
    "    we are allowing for instant effects. This is the norm in the signal\n",
    "    processing literature but no in the Granger Causality VAR models,\n",
    "    although there is no theoretical reason not to include instant effect in\n",
    "    the external input. To avoid instant effects, the user can simply delay\n",
    "    the input by one sample.\n",
    "\n",
    "    A_pval,B_pval are  P-values for each channel (for all delays together)\n",
    "    using the Deviance formalism.\n",
    "\n",
    "    A_Deviance, B_Deviance ,T are Deviance and number of sample used in the\n",
    "    estimation of p-values, and Deviance/T can serve as a measure of effect\n",
    "    size, and can be used to compute generalized R-square: R2 = 1 -\n",
    "    exp(-Devinace/T).\n",
    "\n",
    "    varx(Y,na,X,base,gamma) If base is not a scalar, it is assumed that it\n",
    "    represent basis functions for filters B of size [filter length, number of\n",
    "    basis functions]. B will have size [size(base,2),ydim,xdim], i.e. as many\n",
    "    parameters for each path as basis functions. The actual filters can be\n",
    "    obtained as tensorprod(base,B,2,1);\n",
    "\n",
    "    varx(Y,na,X,nb,gamma) If Y is a cell array, then the model is fit on all\n",
    "    data records in X and Y. All elements in the cell arrays X and Y have to\n",
    "    have the same xdim and ydim, but may have different numer of rows (time\n",
    "    samples).\n",
    "\n",
    "    varx(Y,na) Only fitst the AR portion. To provide gamma, set set x=[] and\n",
    "    nb=0.\n",
    "\n",
    "    If the intention is to only fit a MA model, then the Granger formalism\n",
    "    requires at least an AR portion for each output channel, without the\n",
    "    interaction between ouput channels. If that is the intention, then one\n",
    "    should call this function for each output channel separatelly, e.g.\n",
    "    varx(y(:,i),na,x,nb)\n",
    "\n",
    "    model can be used by varx_display(model) for display. \n",
    "\n",
    "    (c) July 10, 2023 Lucas C Parra\n",
    "        04/11/2024, last version, Lucas Parra\n",
    "    (c) (python) April 12, 2024, Aimar Silvan, based on matlab version 04/11/2024\n",
    "\n",
    "    '''\n",
    "    # If not simulating eXternal MA channel then xdim=0\n",
    "    if X is None or np.all(nb == 0):\n",
    "        X = None\n",
    "        nb = 0\n",
    "        \n",
    "    # Make Y and X into lists if they are not already, to handle multiple data records\n",
    "    if not isinstance(Y, list):\n",
    "        Y = [Y]\n",
    "    if not isinstance(X, list):\n",
    "        X = [X]\n",
    "    \n",
    "    # Get dimensions\n",
    "    ydim = Y[0].shape[1]\n",
    "    xdim = X[0].shape[1] if X[0] is not None else 0\n",
    "        \n",
    "    # Initialize basis functions\n",
    "    \n",
    "    if isinstance(nb, np.ndarray):\n",
    "        m = {'base': nb}  # save for output\n",
    "        # internally, base variable is a list with one base for each dimension\n",
    "        base = [np.eye(na) for _ in range(ydim)]\n",
    "        base.extend([nb for _ in range(xdim)])\n",
    "        nb, bparams = nb.shape  # lags according and number of parameters according to basis\n",
    "    else:\n",
    "        m = {'base': None}  # save for output\n",
    "        base = [None for _ in range(ydim + xdim)]  # empty bases\n",
    "        bparams = nb  # number of parameters same as number of lags\n",
    "    \n",
    "    # number of lags and number of parameters equal ...\n",
    "    lags = np.ones((ydim, 1)) * na\n",
    "    params = lags.copy()\n",
    "    # ... unless using basis function and need only including when modeling MA of external input\n",
    "    if nb:\n",
    "        lags = np.concatenate((lags, np.ones((xdim, 1)) * nb))\n",
    "        params = np.concatenate((params, np.ones((xdim, 1)) * bparams))\n",
    "\n",
    "    # calculate correlations\n",
    "    Rxx = 0\n",
    "    Rxy = 0\n",
    "    ryy = 0\n",
    "    T = 0\n",
    "    for i in range(len(Y)):\n",
    "        # Set preceding output and input both as input to the LS problem\n",
    "        x = Y[i][:-1, :]\n",
    "        y = Y[i][1:, :]\n",
    "        \n",
    "        # if modeling also the MA of eXternal input\n",
    "        if nb:\n",
    "            x = np.concatenate((x, X[i][1:, :]), axis=1)\n",
    "\n",
    "        # Compute auto and cross correlations\n",
    "        Rxx_, Rxy_, ryy_, T_ = myxcorr(x, y, lags)\n",
    "\n",
    "        # accumulate over all data records\n",
    "        Rxx += Rxx_\n",
    "        Rxy += Rxy_\n",
    "        ryy += ryy_\n",
    "        T += T_\n",
    "        \n",
    "    if gamma is None:\n",
    "        gamma = 0\n",
    "    else:\n",
    "        gamma = gamma/np.sqrt(T-np.sum(lags)) # regularization decreasing with degrees of freedom\n",
    "        \n",
    "    AB, s2, Bias = fit_model(Rxx, Rxy, ryy, gamma, base)\n",
    "    \n",
    "    \n",
    "    A = np.transpose(AB[0:ydim*na, :].reshape(na, ydim, ydim, order='F'), (0, 2, 1)) # F so it follows Fortran-style order (consistent with matlab)\n",
    "    B = np.squeeze(np.transpose(AB[ydim*na:].reshape(int(params[-1,0]), xdim, ydim, order='F'), (0, 2 ,1)))\n",
    "\n",
    "    m['A'] = A\n",
    "    m['B'] = B\n",
    "    \n",
    "    # if we used a base, return filters B with base applied\n",
    "    m['B_coeff'] = m['B']\n",
    "    if base[0] is not None:\n",
    "        m['B'] = np.tensordot(m['base'], m['B_coeff'], axes=([1], [0]))\n",
    "    \n",
    "    # Granger Causal test for all inputs (external and recurrent)\n",
    "    xdim = x.shape[1]\n",
    "    Deviance = np.zeros((2, xdim))\n",
    "    pval = np.zeros((2, xdim))\n",
    "    for i in range(xdim-1, -1, -1):\n",
    "        ii = np.arange(0, np.sum(lags)).astype(int)\n",
    "        startidx = int(np.sum(lags[0:i]))\n",
    "        endidx = startidx + int(lags[i,0])\n",
    "        ii = np.delete(ii, np.arange(startidx, endidx).astype(int))\n",
    "        # , np.sum(lags[0:i])+lags[i]))\n",
    "        \n",
    "        _, s2r, Biasr = fit_model(Rxx[ii, :][:, ii], Rxy[ii, :], ryy, gamma, [base[j] for j in range(xdim) if j != i])\n",
    "        \n",
    "        df = T - np.sum(params)  # degrees of freedom of the full model\n",
    "        \n",
    "        Deviance[:, i] = df * np.log(s2r / s2) - T * Biasr + T * Bias  # not the exact formula, but I calibrated and seems to work well for small T\n",
    "        \n",
    "        pval[:, i] = 1 - chi2.cdf(Deviance[:, i], params[i])\n",
    "    \n",
    "    # store additional outputs in model dictionary\n",
    "    m['A_pval'] = pval[:, :ydim]\n",
    "    m['B_pval'] = pval[:, ydim:]\n",
    "    m['A_Deviance'] = Deviance[:, :ydim]\n",
    "    m['B_Deviance'] = Deviance[:, ydim:]\n",
    "    m['T'] = T\n",
    "    \n",
    "    return m\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "# # test varx (without basis)\n",
    "import scipy.io as sio\n",
    "x = sio.loadmat('x.mat')['x']\n",
    "y = sio.loadmat('y.mat')['y']\n",
    "L = 10\n",
    "na = 10; nb = 20; gamma = 0\n",
    "\n",
    "model = varx(y,na,x,nb,gamma)\n",
    "\n",
    "# test varx(with basis)\n",
    "# import scipy.io as sio\n",
    "# x = sio.loadmat('x_basis.mat')['x']\n",
    "# y = sio.loadmat('y_basis.mat')['y']\n",
    "# L = 10\n",
    "# na = 3; nb = 4; gamma = 0.1\n",
    "# base = basis(30, nb, 'normal')\n",
    "# model = varx(y,na,x,base,gamma)\n",
    "\n",
    "\n",
    "# # test basis\n",
    "# import numpy as np\n",
    "\n",
    "# # clear A B\n",
    "# A = np.zeros((3, 2, 2))\n",
    "# B = np.zeros((4,2))\n",
    "\n",
    "# A[:, :, 0] = [[0.9, 0], [-0.5, 0], [0, 0]]\n",
    "# A[:, :, 1] = [[-0.5, 0.5], [0.4, -0.7], [0, 0]]\n",
    "# B[:, :] = [[1, 0], [0.5, 0], [0, 0], [-0.5, 0]]\n",
    "\n",
    "# # Get the dimensions of B and A\n",
    "# nb, ydim = B.shape\n",
    "# na, ydim, _ = A.shape\n",
    "# xdim = 1\n",
    "# # Call the basis function\n",
    "# base = basis(30, nb, 'normal')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
